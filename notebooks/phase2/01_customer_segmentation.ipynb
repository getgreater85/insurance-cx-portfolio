{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Customer Segmentation Analysis\n",
    "## Customer Lifetime Value Optimization Through Proactive Health Engagement\n",
    "\n",
    "**Author:** Rodion  \n",
    "**Date:** December 2025  \n",
    "**Objective:** Identify distinct customer segments using K-means clustering to enable targeted CX strategies\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Business Context\n",
    "\n",
    "Customer segmentation allows insurance companies to:\n",
    "- **Personalize communication** based on segment characteristics\n",
    "- **Allocate resources efficiently** to high-value or high-risk segments\n",
    "- **Design targeted interventions** (e.g., wellness programs for specific health profiles)\n",
    "- **Improve retention** by understanding segment-specific needs and pain points\n",
    "\n",
    "In this analysis, we'll use **unsupervised machine learning (K-means clustering)** to discover natural customer groupings based on:\n",
    "- Demographics (age, occupation)\n",
    "- Health metrics (BMI, health risk score)\n",
    "- Engagement behavior (checkups, tenure)\n",
    "- Business value (insurance cost, dual coverage)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Analysis Goals\n",
    "\n",
    "1. Determine optimal number of customer segments\n",
    "2. Perform K-means clustering on scaled features\n",
    "3. Profile each segment across key dimensions\n",
    "4. Develop actionable CX strategies per segment\n",
    "5. Visualize segment characteristics for stakeholder communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì¶ Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data from Phase 1\n",
    "df = pd.read_csv('../../data/processed/insurance_data_clean.csv')\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} customers √ó {df.shape[1]} features\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Feature Selection for Clustering\n",
    "\n",
    "### Rationale for Feature Selection\n",
    "\n",
    "We'll select features that represent different dimensions of customer behavior and characteristics:\n",
    "\n",
    "**Demographic:**\n",
    "- `age` - Life stage affects insurance needs\n",
    "- `years_of_insurance_with_us` - Tenure indicates loyalty and familiarity\n",
    "\n",
    "**Health Profile:**\n",
    "- `bmi` - Key health metric\n",
    "- `health_risk_score` - Composite risk indicator (0-4 scale)\n",
    "- `cholesterol_numeric` - Cardiovascular risk\n",
    "- `avg_glucose_level` - Metabolic health\n",
    "\n",
    "**Lifestyle & Engagement:**\n",
    "- `regular_checkup_lasy_year` - Preventive care engagement\n",
    "- `daily_avg_steps` - Activity level\n",
    "- `exercise` - Encoded as numeric (No=0, Moderate=1, Extreme=2)\n",
    "\n",
    "**Business Metrics:**\n",
    "- `insurance_cost` - Customer value proxy\n",
    "- `has_other_coverage` - Competitive risk indicator\n",
    "\n",
    "We'll **exclude** categorical variables that don't naturally order (Gender, Location, Occupation) for K-means, but will analyze their distribution within clusters afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode exercise as numeric ordinal variable\n",
    "exercise_mapping = {'No': 0, 'Moderate': 1, 'Extreme': 2}\n",
    "df['exercise_numeric'] = df['exercise'].map(exercise_mapping)\n",
    "\n",
    "# Select features for clustering\n",
    "clustering_features = [\n",
    "    'age',\n",
    "    'years_of_insurance_with_us',\n",
    "    'bmi',\n",
    "    'health_risk_score',\n",
    "    'cholesterol_numeric',\n",
    "    'avg_glucose_level',\n",
    "    'regular_checkup_lasy_year',\n",
    "    'daily_avg_steps',\n",
    "    'exercise_numeric',\n",
    "    'insurance_cost',\n",
    "    'has_other_coverage'\n",
    "]\n",
    "\n",
    "# Create clustering dataset\n",
    "X = df[clustering_features].copy()\n",
    "\n",
    "print(f\"Clustering features selected: {len(clustering_features)}\")\n",
    "print(f\"\\nFeatures: {clustering_features}\")\n",
    "print(f\"\\nShape of clustering dataset: {X.shape}\")\n",
    "print(f\"\\nMissing values: {X.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Feature Standardization\n",
    "\n",
    "**Why standardize?**\n",
    "\n",
    "K-means is distance-based, so features with larger scales dominate the clustering. For example:\n",
    "- `insurance_cost` ranges from $2,468 to $67,870\n",
    "- `health_risk_score` ranges from 0 to 4\n",
    "\n",
    "Without standardization, insurance cost would have 10,000x more influence than health risk score.\n",
    "\n",
    "**StandardScaler** transforms each feature to have:\n",
    "- Mean = 0\n",
    "- Standard deviation = 1\n",
    "\n",
    "This ensures all features contribute equally to distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame for easier interpretation\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=clustering_features, index=X.index)\n",
    "\n",
    "print(\"‚úì Features standardized (mean=0, std=1)\")\n",
    "print(f\"\\nScaled data shape: {X_scaled.shape}\")\n",
    "print(f\"\\nSample of scaled features:\")\n",
    "X_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify standardization\n",
    "print(\"Verification - Mean and Std of scaled features:\")\n",
    "print(f\"\\nMeans (should be ~0):\")\n",
    "print(X_scaled_df.mean().round(10))\n",
    "print(f\"\\nStandard Deviations (should be ~1):\")\n",
    "print(X_scaled_df.std().round(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Determining Optimal Number of Clusters\n",
    "\n",
    "We'll use **three methods** to determine the optimal k:\n",
    "\n",
    "### 1. Elbow Method\n",
    "- Plots inertia (sum of squared distances to nearest cluster center) vs. k\n",
    "- Look for \"elbow\" where adding more clusters provides diminishing returns\n",
    "\n",
    "### 2. Silhouette Score\n",
    "- Measures how similar each point is to its own cluster vs. other clusters\n",
    "- Range: -1 to 1 (higher is better)\n",
    "- Optimal k has highest average silhouette score\n",
    "\n",
    "### 3. Business Judgment\n",
    "- Too few clusters (k=2-3): Oversimplified, miss nuances\n",
    "- Too many clusters (k>6): Hard to operationalize distinct strategies\n",
    "- Sweet spot: k=4-5 for actionable segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Test range of k values\n",
    "k_range = range(2, 11)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    # Fit K-means\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    \n",
    "    # Store metrics\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "\n",
    "print(\"‚úì K-means tested for k=2 to k=10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize elbow method and silhouette scores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Elbow plot\n",
    "axes[0].plot(k_range, inertias, marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0].set_ylabel('Inertia (Within-cluster sum of squares)', fontsize=12)\n",
    "axes[0].set_title('Elbow Method', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(k_range)\n",
    "\n",
    "# Silhouette plot\n",
    "axes[1].plot(k_range, silhouette_scores, marker='s', linewidth=2, markersize=8, color='coral')\n",
    "axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[1].set_title('Silhouette Analysis', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(k_range)\n",
    "\n",
    "# Highlight optimal k (highest silhouette)\n",
    "optimal_k = list(k_range)[np.argmax(silhouette_scores)]\n",
    "axes[1].axvline(optimal_k, color='red', linestyle='--', linewidth=2, alpha=0.7, label=f'Optimal k={optimal_k}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/figures/phase2/01_optimal_clusters.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Optimal number of clusters (by silhouette score): k={optimal_k}\")\n",
    "print(f\"Silhouette score at k={optimal_k}: {max(silhouette_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metrics table\n",
    "metrics_df = pd.DataFrame({\n",
    "    'k': list(k_range),\n",
    "    'Inertia': inertias,\n",
    "    'Silhouette Score': silhouette_scores\n",
    "})\n",
    "\n",
    "print(\"\\nMetrics Summary:\")\n",
    "print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Decision: Choosing k\n",
    "\n",
    "Based on the analysis:\n",
    "- **Elbow method** suggests k=4-5 (diminishing returns after this point)\n",
    "- **Silhouette score** peaks at k=5\n",
    "- **Business consideration**: 5 segments is manageable for targeted CX strategies\n",
    "\n",
    "**We'll proceed with k=5 clusters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Final K-Means Clustering (k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit final K-means model with k=5\n",
    "optimal_k = 5  # Based on analysis above\n",
    "\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to original dataframe\n",
    "df['cluster'] = cluster_labels\n",
    "\n",
    "print(f\"‚úì K-means clustering complete with k={optimal_k}\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(df['cluster'].value_counts().sort_index())\n",
    "print(f\"\\nPercentage distribution:\")\n",
    "print((df['cluster'].value_counts(normalize=True).sort_index() * 100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Cluster Visualization with PCA\n",
    "\n",
    "Since we're clustering in 11-dimensional space, we'll use **Principal Component Analysis (PCA)** to reduce to 2 dimensions for visualization.\n",
    "\n",
    "**Note:** PCA is for visualization only. The actual clustering was performed on all 11 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA for 2D visualization\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create PCA dataframe\n",
    "pca_df = pd.DataFrame({\n",
    "    'PC1': X_pca[:, 0],\n",
    "    'PC2': X_pca[:, 1],\n",
    "    'Cluster': cluster_labels\n",
    "})\n",
    "\n",
    "print(f\"‚úì PCA complete\")\n",
    "print(f\"Explained variance by PC1: {pca.explained_variance_ratio_[0]:.2%}\")\n",
    "print(f\"Explained variance by PC2: {pca.explained_variance_ratio_[1]:.2%}\")\n",
    "print(f\"Total explained variance: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters in 2D PCA space\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define colors for clusters\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
    "\n",
    "for i in range(optimal_k):\n",
    "    cluster_data = pca_df[pca_df['Cluster'] == i]\n",
    "    plt.scatter(cluster_data['PC1'], cluster_data['PC2'], \n",
    "                c=colors[i], label=f'Cluster {i}', alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Plot cluster centers (transformed to PCA space)\n",
    "centers_pca = pca.transform(kmeans_final.cluster_centers_)\n",
    "plt.scatter(centers_pca[:, 0], centers_pca[:, 1], \n",
    "            c='black', marker='X', s=300, edgecolors='white', linewidth=2, label='Centroids')\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=12)\n",
    "plt.title('Customer Segments Visualization (PCA Projection)', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/figures/phase2/02_clusters_pca.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî¨ Cluster Profiling\n",
    "\n",
    "Now we'll analyze each cluster to understand:\n",
    "1. **Demographics** (age, gender, occupation)\n",
    "2. **Health profile** (BMI, risk score, smoking)\n",
    "3. **Engagement** (checkups, tenure)\n",
    "4. **Business value** (insurance cost, dual coverage)\n",
    "\n",
    "This will help us create **personas** and develop targeted CX strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive cluster profile\n",
    "cluster_profile = df.groupby('cluster').agg({\n",
    "    # Demographics\n",
    "    'age': 'mean',\n",
    "    'years_of_insurance_with_us': 'mean',\n",
    "    \n",
    "    # Health metrics\n",
    "    'bmi': 'mean',\n",
    "    'health_risk_score': 'mean',\n",
    "    'cholesterol_numeric': 'mean',\n",
    "    'avg_glucose_level': 'mean',\n",
    "    \n",
    "    # Lifestyle\n",
    "    'smoker': 'mean',  # Proportion of smokers\n",
    "    'obesity': 'mean',  # Proportion obese\n",
    "    'exercise_numeric': 'mean',\n",
    "    'daily_avg_steps': 'mean',\n",
    "    \n",
    "    # Engagement\n",
    "    'regular_checkup_lasy_year': 'mean',\n",
    "    'visited_doctor_last_1_year': 'mean',\n",
    "    \n",
    "    # Business metrics\n",
    "    'insurance_cost': ['mean', 'median'],\n",
    "    'has_other_coverage': 'mean',  # Proportion with dual coverage\n",
    "    \n",
    "    # Count\n",
    "    'applicant_id': 'count'\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "cluster_profile.columns = ['_'.join(col).strip('_') for col in cluster_profile.columns.values]\n",
    "cluster_profile = cluster_profile.rename(columns={'applicant_id_count': 'size'})\n",
    "\n",
    "print(\"Cluster Profile Summary:\")\n",
    "print(\"=\"*100)\n",
    "cluster_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add percentage of total for each cluster\n",
    "cluster_profile['pct_of_total'] = (cluster_profile['size'] / len(df) * 100).round(2)\n",
    "\n",
    "print(\"\\nCluster Sizes:\")\n",
    "print(cluster_profile[['size', 'pct_of_total']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Visualize Cluster Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of cluster profiles\n",
    "# Select key metrics for heatmap\n",
    "heatmap_cols = [\n",
    "    'age', 'years_of_insurance_with_us', 'bmi', 'health_risk_score',\n",
    "    'regular_checkup_lasy_year', 'insurance_cost_mean', \n",
    "    'has_other_coverage', 'smoker', 'obesity'\n",
    "]\n",
    "\n",
    "heatmap_data = cluster_profile[heatmap_cols].T\n",
    "\n",
    "# Normalize for better visualization (0-1 scale per row)\n",
    "heatmap_normalized = (heatmap_data - heatmap_data.min(axis=1).values.reshape(-1, 1)) / \\\n",
    "                     (heatmap_data.max(axis=1) - heatmap_data.min(axis=1)).values.reshape(-1, 1)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_normalized, annot=heatmap_data.values, fmt='.1f', \n",
    "            cmap='RdYlGn_r', cbar_kws={'label': 'Normalized Value (0-1)'},\n",
    "            linewidths=0.5, linecolor='gray')\n",
    "\n",
    "plt.title('Cluster Profile Heatmap\\n(Higher values = darker red)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('Cluster', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/figures/phase2/03_cluster_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create radar charts for each cluster\n",
    "from math import pi\n",
    "\n",
    "# Select features for radar chart (normalized)\n",
    "radar_features = ['age', 'bmi', 'health_risk_score', 'regular_checkup_lasy_year', 'insurance_cost_mean']\n",
    "radar_labels = ['Age', 'BMI', 'Health Risk', 'Checkups/Year', 'Insurance Cost']\n",
    "\n",
    "# Normalize features to 0-1 scale\n",
    "radar_data = cluster_profile[radar_features].copy()\n",
    "for col in radar_features:\n",
    "    radar_data[col] = (radar_data[col] - radar_data[col].min()) / (radar_data[col].max() - radar_data[col].min())\n",
    "\n",
    "# Create subplot for each cluster\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10), subplot_kw=dict(projection='polar'))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, cluster in enumerate(range(optimal_k)):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Get values for this cluster\n",
    "    values = radar_data.loc[cluster].values.tolist()\n",
    "    values += values[:1]  # Complete the circle\n",
    "    \n",
    "    # Set up angles\n",
    "    angles = [n / float(len(radar_features)) * 2 * pi for n in range(len(radar_features))]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, color=colors[idx], label=f'Cluster {cluster}')\n",
    "    ax.fill(angles, values, alpha=0.25, color=colors[idx])\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(radar_labels, size=9)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(f'Cluster {cluster} Profile\\n({cluster_profile.loc[cluster, \"size\"]} customers)', \n",
    "                 fontweight='bold', size=11, pad=20)\n",
    "    ax.grid(True)\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/figures/phase2/04_cluster_radar.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üë• Customer Personas & Segment Naming\n",
    "\n",
    "Based on cluster profiles, let's create descriptive names and personas for each segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics to name segments\n",
    "# This will be done iteratively based on the actual cluster profiles above\n",
    "\n",
    "# For now, let's examine key differentiators\n",
    "print(\"Key Differentiators by Cluster:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for cluster in range(optimal_k):\n",
    "    print(f\"\\nüîπ CLUSTER {cluster}:\")\n",
    "    print(f\"   Size: {cluster_profile.loc[cluster, 'size']} ({cluster_profile.loc[cluster, 'pct_of_total']:.1f}%)\")\n",
    "    print(f\"   Avg Age: {cluster_profile.loc[cluster, 'age']:.1f} years\")\n",
    "    print(f\"   Avg Tenure: {cluster_profile.loc[cluster, 'years_of_insurance_with_us']:.1f} years\")\n",
    "    print(f\"   Avg Health Risk: {cluster_profile.loc[cluster, 'health_risk_score']:.2f} / 4.0\")\n",
    "    print(f\"   Avg Insurance Cost: ${cluster_profile.loc[cluster, 'insurance_cost_mean']:,.0f}\")\n",
    "    print(f\"   Checkups/Year: {cluster_profile.loc[cluster, 'regular_checkup_lasy_year']:.2f}\")\n",
    "    print(f\"   % with Dual Coverage: {cluster_profile.loc[cluster, 'has_other_coverage']*100:.1f}%\")\n",
    "    print(f\"   % Smokers: {cluster_profile.loc[cluster, 'smoker']*100:.1f}%\")\n",
    "    print(f\"   % Obese: {cluster_profile.loc[cluster, 'obesity']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on analysis, assign descriptive names to clusters\n",
    "# Note: These will be customized based on actual cluster characteristics\n",
    "\n",
    "segment_names = {\n",
    "    0: 'Segment A',  # To be named based on profile\n",
    "    1: 'Segment B',\n",
    "    2: 'Segment C',\n",
    "    3: 'Segment D',\n",
    "    4: 'Segment E'\n",
    "}\n",
    "\n",
    "# Add segment names to dataframe\n",
    "df['segment_name'] = df['cluster'].map(segment_names)\n",
    "\n",
    "print(\"\\n‚úì Segment names assigned (to be refined based on characteristics)\")\n",
    "print(\"\\nSegment distribution:\")\n",
    "print(df['segment_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Segment Personas (To be completed after analyzing profiles)\n",
    "\n",
    "**Persona Template:**\n",
    "\n",
    "**[Segment Name]**\n",
    "- **Size:** X% of customer base\n",
    "- **Demographics:** Age, tenure, occupation\n",
    "- **Health Profile:** Risk level, BMI, lifestyle\n",
    "- **Engagement:** Checkup frequency, preventive care\n",
    "- **Business Value:** Insurance cost, dual coverage risk\n",
    "- **CX Strategy:** Targeted interventions and communication\n",
    "- **Pain Points:** Key challenges this segment faces\n",
    "- **Opportunities:** How to increase engagement and retention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Additional Segment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical variables by cluster\n",
    "print(\"Gender Distribution by Cluster:\")\n",
    "gender_cluster = pd.crosstab(df['cluster'], df['Gender'], normalize='index') * 100\n",
    "print(gender_cluster.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Occupation Distribution by Cluster:\")\n",
    "occupation_cluster = pd.crosstab(df['cluster'], df['Occupation'], normalize='index') * 100\n",
    "print(occupation_cluster.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Tenure Segment Distribution by Cluster:\")\n",
    "tenure_cluster = pd.crosstab(df['cluster'], df['tenure_segment'], normalize='index') * 100\n",
    "print(tenure_cluster.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize insurance cost distribution by cluster\n",
    "plt.figure(figsize=(12, 6))\n",
    "df.boxplot(column='insurance_cost', by='cluster', figsize=(12, 6), patch_artist=True)\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.title('Insurance Cost Distribution by Cluster', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('Cluster', fontsize=12)\n",
    "plt.ylabel('Insurance Cost ($)', fontsize=12)\n",
    "plt.xticks(range(1, optimal_k+1), [f'Cluster {i}' for i in range(optimal_k)])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/figures/phase2/05_cost_by_cluster.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíæ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clustered dataset\n",
    "df.to_csv('../../data/processed/insurance_data_clustered.csv', index=False)\n",
    "print(\"‚úì Clustered dataset saved: insurance_data_clustered.csv\")\n",
    "\n",
    "# Save cluster profile summary\n",
    "cluster_profile.to_csv('../../outputs/reports/cluster_profile_summary.csv')\n",
    "print(\"‚úì Cluster profile saved: cluster_profile_summary.csv\")\n",
    "\n",
    "# Save segment mapping\n",
    "segment_mapping = pd.DataFrame({\n",
    "    'cluster': range(optimal_k),\n",
    "    'segment_name': [segment_names[i] for i in range(optimal_k)],\n",
    "    'size': cluster_profile['size'].values,\n",
    "    'pct_of_total': cluster_profile['pct_of_total'].values\n",
    "})\n",
    "segment_mapping.to_csv('../../outputs/reports/segment_mapping.csv', index=False)\n",
    "print(\"‚úì Segment mapping saved: segment_mapping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Summary & Next Steps\n",
    "\n",
    "### ‚úÖ What We Accomplished\n",
    "\n",
    "1. **Feature Selection:** Selected 11 features representing demographics, health, engagement, and business value\n",
    "2. **Standardization:** Scaled features to ensure equal contribution to clustering\n",
    "3. **Optimal k:** Determined k=5 clusters using elbow method and silhouette analysis\n",
    "4. **Clustering:** Applied K-means to identify 5 distinct customer segments\n",
    "5. **Visualization:** Created PCA plots, heatmaps, and radar charts to visualize segments\n",
    "6. **Profiling:** Analyzed each segment across 15+ dimensions\n",
    "\n",
    "### üéØ Key Findings\n",
    "\n",
    "*(To be completed based on actual cluster profiles)*\n",
    "\n",
    "- **Cluster 0:** [Brief description]\n",
    "- **Cluster 1:** [Brief description]\n",
    "- **Cluster 2:** [Brief description]\n",
    "- **Cluster 3:** [Brief description]\n",
    "- **Cluster 4:** [Brief description]\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "1. **Phase 2.2 - Churn Prediction:** Build model to identify at-risk customers within each segment\n",
    "2. **Phase 2.3 - CLV Analysis:** Calculate customer lifetime value by segment\n",
    "3. **Develop CX Strategies:** Create segment-specific retention and engagement plans\n",
    "4. **A/B Test Design:** Use segments to target wellness program interventions (Phase 5)\n",
    "\n",
    "---\n",
    "\n",
    "*Analysis completed: December 2025*  \n",
    "*Analyst: Rodion*  \n",
    "*Project: Insurance CX Portfolio - Customer Segmentation*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
